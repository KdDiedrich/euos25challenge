{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14540892,"sourceType":"datasetVersion","datasetId":9266155,"isSourceIdPinned":true}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Packages and initial setup","metadata":{}},{"cell_type":"code","source":"!pip install Catboost lightgbm optuna-integration rdkit","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from catboost import CatBoostClassifier\nfrom functools import partial\nfrom lightgbm import LGBMClassifier\nimport joblib\nimport numpy as np\nimport optuna\nimport os\nimport pandas as pd\nfrom pathlib import Path\n\nfrom rdkit import Chem\nfrom rdkit.Chem import AllChem\nfrom rdkit.Chem import (\n    MolFromSmiles,\n    MolToSmiles,\n    DataStructs,\n    Descriptors,\n    Mol,\n    MACCSkeys\n)\nfrom rdkit.Chem.rdFingerprintGenerator import (\n    GetMorganGenerator,\n    GetRDKitFPGenerator,\n    GetTopologicalTorsionGenerator\n)\nfrom rdkit.Chem import rdMolDescriptors\nfrom rdkit.ML.Descriptors.MoleculeDescriptors import MolecularDescriptorCalculator\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\n\nimport time\nimport warnings\nfrom xgboost import XGBClassifier, XGBRegressor\n\nRANDOM_STATE = 10\nINPUT_DIR = Path(\"/kaggle/input/euos25\")\nWORKING_DIR = Path(\"/kaggle/working\")\n\npd.set_option(\n    \"display.float_format\",\n    lambda x: \"%.0f\" % x if x.is_integer() else \"%.3f\" % x\n)\n\n# Suppress annoying but non-critical LGB warning about missing feature names\nwarnings.filterwarnings(\n    \"ignore\",\n    message=\"X does not have valid feature names, but LGBM\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"t340_filename = \"euos25_challenge_train_transmittance340.csv\"\nt450_679_avg_filename = \"euos25_challenge_train_transmittance450.csv\"\nf340_450_filename = \"euos25_challenge_train_fluorescence340_450.csv\"\nfmulti_filename = \"euos25_challenge_train_fluorescence480.csv\"\n\ntest_filename = \"euos25_challenge_test.csv\"\n\ndf_t340 = pd.read_csv(INPUT_DIR / t340_filename)\ndf_t450_679 = pd.read_csv(INPUT_DIR / t450_679_avg_filename)\ndf_f340_450 = pd.read_csv(INPUT_DIR / f340_450_filename)\ndf_fmulti = pd.read_csv(INPUT_DIR / fmulti_filename)\n\nt340ext_filename = (\"euos25_challenge_train_transmittance340_extended.csv\")\nt450_679_avgext_filename = (\"euos25_challenge_train_transmittance450_extended.csv\")\nf340_450ext_filename = (\"euos25_challenge_train_fluorescence340_450_extended.csv\")\nfmultiext_filename = (\"euos25_challenge_train_fluorescence480_extended.csv\")\nleaderboard_filename = (\"euos_challenge_2025_leaderboard.csv\")\n\ndf_t340ext = pd.read_csv(INPUT_DIR / t340ext_filename)\ndf_t450_679ext = pd.read_csv(INPUT_DIR / t450_679_avgext_filename)\ndf_f340_450ext = pd.read_csv(INPUT_DIR / f340_450ext_filename)\ndf_fmultiext = pd.read_csv(INPUT_DIR / fmultiext_filename)\ndf_leaderboard = pd.read_csv(INPUT_DIR / leaderboard_filename)\ndf_test = pd.read_csv(INPUT_DIR / test_filename)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_t340[\"canonical_smiles\"] = df_t340[\"SMILES\"].apply(\n    lambda smiles: MolToSmiles(MolFromSmiles(smiles))\n)\n\nif (df_t340[\"canonical_smiles\"].duplicated().any()):\n    print(\"Duplicated SMILES detected after canonicalization.\")\nelse:\n    print(\"No duplicated SMILES detected after canonicalization.\")\n\n# All files contains the same molecules\n# -> merge\ndf_train = pd.DataFrame(\n    {\n        \"id\": df_t340[\"N\"],\n        \"canonical_smiles\": df_t340[\"canonical_smiles\"],\n        \"t340\": df_t340[\"Transmittance (qualitative)\"],\n        \"t450_679\": df_t450_679[\"Transmittance\"],\n        \"f340_450\": df_f340_450[\"Fluorescence\"],\n        \"fmulti\": df_fmulti[\"Fluorescence\"]\n    }\n)\n\ndf_leaderboard[\"canonical_smiles\"] = df_leaderboard[\"SMILES\"].apply(\n    lambda smiles: MolToSmiles(MolFromSmiles(smiles))\n)\n\nif (df_leaderboard[\"canonical_smiles\"].duplicated().any()):\n    print(\"Duplicated SMILES detected after canonicalization.\")\nelse:\n    print(\"No duplicated SMILES detected after canonicalization.\")\n\ndf_leaderboard = df_leaderboard.drop(columns=[\"SMILES\"])\ndf_leaderboard = df_leaderboard.rename(\n    columns={\n        \"ID\": \"id\",\n        \"Transmittance(340)\": \"t340\",\n        \"Transmittance(450)\": \"t450_679\",\n        \"Fluorescence(340/450)\": \"f340_450\",\n        \"Fluorescence(>480)\": \"fmulti\",\n    }\n)\n\ndf_train_full = pd.concat(\n    [\n        df_train.assign(\n            source=\"train\",\n            source_index=df_train.index,\n        ),\n        df_leaderboard.assign(\n            source=\"leaderboard\",\n            source_index=df_leaderboard.index,\n        )\n    ],\n    ignore_index=True,\n)\n\ndf_test[\"canonical_smiles\"] = df_test[\"SMILES\"].apply(\n    lambda smiles: MolToSmiles(MolFromSmiles(smiles))\n)\n\nif (df_test[\"canonical_smiles\"].duplicated().any()):\n    print(\"Duplicated SMILES detected after canonicalization.\")\nelse:\n    print(\"No duplicated SMILES detected after canonicalization.\")\n\ndf_test = df_test.rename(columns={\"ID\": \"id\"})\n\nX_train_features = {}\nX_test_features = {}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Features","metadata":{}},{"cell_type":"code","source":"def featurize_fp(\n        smiles_list: np.ndarray,\n        fp_type: str,\n        file_path: Path | None\n) -> np.ndarray:\n    if file_path is not None and file_path.exists():\n        print(f\"Loading fingerprints from {file_path}...\")\n        return np.load(file_path)\n\n    fps = []\n\n    fp_type = fp_type.lower()\n\n    if fp_type == \"maccskeys\":\n        n_bits = 167\n        generator = None\n    else:\n        n_bits = 2048\n\n        if fp_type == \"morgan\":\n            generator = GetMorganGenerator(radius=2, fpSize=n_bits)\n\n        elif fp_type == \"rdkit\":\n            generator = GetRDKitFPGenerator(fpSize=n_bits, minPath=1, maxPath=7)\n\n        elif fp_type == \"atompair\":\n            generator = GetAtomPairGenerator(fpSize=n_bits)\n\n        elif fp_type == \"torsion\":\n            generator = GetTopologicalTorsionGenerator(fpSize=n_bits)\n\n        else:\n            raise ValueError(f\"Unknown fingerprint type: {fp_type}\")\n\n    for smiles in smiles_list:\n        mol = MolFromSmiles(smiles)\n        if mol is None:\n            print(\"SMILES conversion failed.\")\n            fps.append(np.zeros(n_bits, dtype=int))\n            continue\n\n        try:\n            if fp_type == \"maccskeys\":\n                fp = MACCSkeys.GenMACCSKeys(mol)\n            else:\n                fp = generator.GetFingerprint(mol)\n        except Exception as e:\n            print(f\"Fingerprint generation failed.\")\n            fps.append(np.zeros(n_bits, dtype=int))\n            continue\n\n        arr = np.zeros(n_bits, dtype=int)\n        DataStructs.ConvertToNumpyArray(fp, arr)\n        fps.append(arr)\n\n    if file_path is not None:\n        np.save(file_path, fps)\n        print(f\"Saved fingerprints to {file_path}.\")\n\n    return np.vstack(fps)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def featurize_desc2D(\n        smiles_list: np.ndarray,\n        file_path: Path = None\n) -> np.ndarray:\n    if file_path is not None and file_path.exists():\n        print(f\"Loading 2D descriptors from {file_path}...\")\n        return np.load(file_path)\n\n    desc_names = [desc[0] for desc in Descriptors._descList]\n    n_descs = len(desc_names)\n    desc_data = []\n\n    for smiles in smiles_list:\n        mol = Chem.MolFromSmiles(smiles)\n        if mol is None:\n            print(\"SMILES conversion failed.\")\n            desc_data.append(np.zeros(n_descs, dtype=float))\n            continue\n\n        try:\n            descs_dict = Descriptors.CalcMolDescriptors(mol)\n            # Extract only values in the consistent order\n            descs_values = [descs_dict[name] for name in desc_names]\n        except Exception as e:\n            print(\"2D descriptor calculation failed.\")\n            desc_data.append(np.zeros(n_descs, dtype=float))\n            continue\n\n        desc_data.append(descs_values)\n\n        imputer = SimpleImputer(strategy=\"mean\")\n        desc_data_imputed = imputer.fit_transform(desc_data)\n\n    return desc_data_imputed","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_morganfp = featurize_fp(\n    df_train_full[\"canonical_smiles\"].values,\n    \"morgan\",\n    INPUT_DIR / \"X_train_morganfp.npy\"\n)\n\nX_train_features[\"morganfp\"] = X_morganfp\n\nX_morganfp = featurize_fp(\n    df_test[\"canonical_smiles\"].values,\n    \"morgan\",\n    INPUT_DIR / \"X_test_morganfp.npy\"\n)\n\nX_test_features[\"morganfp\"] = X_morganfp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_rdkitfp = featurize_fp(\n    df_train_full[\"canonical_smiles\"].values,\n    \"rdkit\",\n     INPUT_DIR / \"X_train_rdkitfp.npy\"\n)\n\nX_train_features[\"rdkitfp\"] = X_rdkitfp\n\nX_rdkitfp = featurize_fp(\n    df_test[\"canonical_smiles\"].values,\n    \"rdkit\",\n     INPUT_DIR / \"X_test_rdkitfp.npy\"\n)\n\nX_test_features[\"rdkitfp\"] = X_rdkitfp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_torsionfp = featurize_fp(\n    df_train_full[\"canonical_smiles\"].values,\n    \"torsion\",\n    INPUT_DIR / \"X_train_torsionfp.npy\"\n)\n\nX_train_features[\"torsionfp\"] = X_torsionfp\n\nX_torsionfp = featurize_fp(\n    df_test[\"canonical_smiles\"].values,\n    \"torsion\",\n    INPUT_DIR / \"X_test_torsionfp.npy\"\n)\n\nX_test_features[\"torsionfp\"] = X_torsionfp","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_maccskeys = featurize_fp(\n    df_train_full[\"canonical_smiles\"].values,\n    \"maccskeys\",\n    INPUT_DIR / \"X_train_maccskeys.npy\"\n)\n\nX_train_features[\"maccskeys\"] = X_maccskeys\n\nX_maccskeys = featurize_fp(\n    df_test[\"canonical_smiles\"].values,\n    \"maccskeys\",\n    INPUT_DIR / \"X_test_maccskeys.npy\"\n)\n\nX_test_features[\"maccskeys\"] = X_maccskeys","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_desc2D = featurize_desc2D(\n    df_train_full[\"canonical_smiles\"].values,\n    INPUT_DIR / \"X_train_desc2D.npy\"\n)\nX_train_features[\"desc2D\"] = X_desc2D\n\nX_desc2D = featurize_desc2D(\n    df_test[\"canonical_smiles\"].values,\n    INPUT_DIR / \"X_test_desc2D.npy\"\n)\nX_test_features[\"desc2D\"] = X_desc2D","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"def get_params(\n        model_type: str,\n        scale_pos_weight: float | None = None\n    ) -> dict:\n    if model_type == \"cb\":\n        params = {\n            \"thread_count\": -1,\n            \"logging_level\": \"Silent\",\n            \"auto_class_weights\": \"Balanced\",\n            \"iterations\": 1000,\n            \"learning_rate\": 0.05,\n            \"depth\": 6,\n            \"rsm\": 0.8,\n            \"eval_metric\": \"AUC\",\n        }\n\n    elif model_type == \"hgb\":\n        params = {\n            \"max_iter\": 500,\n            \"max_leaf_nodes\": 31,\n            \"learning_rate\": 0.05,\n            \"early_stopping\": True,\n        }\n\n    elif model_type == \"xgb\":\n        params = {\n            \"n_jobs\": -1,\n            \"scale_pos_weight\": scale_pos_weight,\n            \"n_estimators\": 500,\n            \"max_depth\": 5,\n            \"learning_rate\": 0.05,\n            \"subsample\": 0.8,\n            \"colsample_bytree\": 0.8,\n            \"eval_metric\": \"auc\",\n        }\n\n    elif model_type == \"lgbm\":\n        params = {\n            \"scale_pos_weight\": scale_pos_weight,\n            \"objective\": \"binary\",\n            \"metric\": \"auc\",\n            \"n_estimators\": 500,\n            \"num_leaves\": 31,\n            \"min_data_in_leaf\": 20,\n            \"learning_rate\": 0.05,\n            \"feature_fraction\": 0.8,\n            \"n_jobs\": -1,\n            \"verbose\": -1,\n        }\n\n    else:\n        raise ValueError(f\"Unknown model type: {model_type}\")\n\n    return params\n\n\ndef get_model(model_type: str, params: dict):\n    if model_type == \"cb\":\n        return CatBoostClassifier(\n            **params\n        )\n\n    elif model_type == \"hgb\":\n        return HistGradientBoostingClassifier(\n            **params\n        )\n\n    elif model_type == \"xgb\":\n        return XGBClassifier(\n            **params\n        )\n\n    elif model_type == \"lgbm\":\n        return LGBMClassifier(\n            **params\n        )\n\n    else:\n        raise ValueError(f\"Unknown model type: {model_type}\")\n\n\ndef fit_model(\n    X_train: np.ndarray,\n    y_train: np.ndarray,\n    model: object\n) -> object:\n    if isinstance(model, LGBMClassifier):\n        model.fit(\n            X_train,\n            y_train,\n            eval_metric=\"auc\"\n        )\n\n    elif isinstance(model, XGBClassifier):\n        model.fit(\n            X_train,\n            y_train,\n            verbose=False,\n        )\n\n    elif isinstance(model, CatBoostClassifier):\n        model.fit(\n            X_train,\n            y_train,\n            verbose=False,\n        )\n\n    elif isinstance(model, HistGradientBoostingClassifier):\n        model.fit(X_train, y_train)\n\n    else:\n        model.fit(X_train, y_train)\n\n    return model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_eval_skfold(\n    df_train_full: pd.DataFrame,\n    df_test: pd.DataFrame,\n    dataset_name,\n    features_train: dict,\n    features_test: dict,\n    feature_names: list,\n    model_type: str,\n    random_state: int\n) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, list]:\n    model_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\n\n    print(\n        f\"{model_name} ({feature_names}, {dataset_name})\"\n    )\n\n    X_train_full = np.hstack([features_train[feature_name] for feature_name in feature_names])\n    y_train_full = df_train_full[dataset_name].values\n    ids_train_full = df_train_full[\"id\"].values\n\n    X_test = np.hstack([features_test[feature_name] for feature_name in feature_names])\n    ids_test = df_test[\"id\"].values\n\n    skf = StratifiedKFold(\n        n_splits=5,\n        shuffle=True,\n        random_state=random_state\n    )\n\n    eval_aucs = []\n    eval_preds = []\n    ensemble_test_preds = []\n    all_df_folds_test_preds = []\n    models = []\n\n    for i, (train_indices, eval_indices) in enumerate(skf.split(X_train_full, y_train_full)):\n        fold_nr = i + 1\n        fold_name = model_name + \"_kfold_\" + str(fold_nr)\n        \n        X_train = X_train_full[train_indices]\n        y_train = y_train_full[train_indices]\n\n        scale_pos_weight = (y_train == 0).sum() / max((y_train == 1).sum(), 1)\n        params = get_params(model_type, scale_pos_weight)\n        model = get_model(model_type, params)\n        \n        model = fit_model(\n            X_train,\n            y_train,\n            model\n        )\n        models.append(model)\n\n        X_eval = X_train_full[eval_indices]\n        y_eval = y_train_full[eval_indices]\n        \n        y_eval_pred_proba = model.predict_proba(X_eval)[:, 1]\n        y_eval_pred_class = model.predict(X_eval)\n\n        # Kfold evaluation\n        auc_eval = roc_auc_score(y_eval, y_eval_pred_proba)\n        eval_aucs.append({\n            \"model\": model_name,\n            \"fold\": fold_nr,\n            \"auc\": auc_eval\n        })\n        \n        ids_eval = ids_train_full[eval_indices]\n        for id_eval, y_proba, y_class in zip(ids_eval, y_eval_pred_proba, y_eval_pred_class):\n            eval_preds.append({\n                \"model\": model_name,\n                \"fold\": fold_nr,\n                \"id\": id_eval,\n                \"y_proba\": y_proba,\n                \"y_class\": y_class\n            })\n\n        # Test set evaluation\n        y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n        y_test_pred_class = model.predict(X_test)\n\n        # Single fold predictions\n        folds_test_preds = []\n        for id_test, y_proba, y_class in zip(ids_test, y_test_pred_proba, y_test_pred_class):\n            folds_test_preds.append({\n                    \"id\": id_test,\n                    \"y_proba\": y_proba\n            })\n        df_folds_test_preds = pd.DataFrame(folds_test_preds)\n        df_folds_test_preds.to_csv(f\"./{model_name}/{fold_name}_test_preds.csv\", index=False)\n        all_df_folds_test_preds.append(df_folds_test_preds)\n\n        # Ensemble predictions accross all folds\n        for id_test, y_proba in zip(ids_test, y_test_pred_proba):\n            ensemble_test_preds.append({\n                \"fold\": fold_nr,\n                \"id\": id_test,\n                \"y_proba\": y_proba\n            })\n                \n        joblib.dump(model, f\"./{model_name}/{fold_name}.joblib\")\n\n    df_eval_aucs = pd.DataFrame(eval_aucs)\n    df_eval_aucs.to_csv(f\"./{model_name}/{model_name}_kfolds_eval_aucs.csv\", index=False)\n    \n    df_eval_preds = pd.DataFrame(eval_preds)\n    df_eval_preds.to_csv(f\"./{model_name}/{model_name}_kfolds_eval_preds.csv\", index=False)\n\n    df_ensemble_test_preds = pd.DataFrame(ensemble_test_preds)\n    df_ensemble_test_preds = (\n        df_ensemble_test_preds\n        .groupby(\"id\", as_index=False)\n        .agg(\n            y_proba=(\"y_proba\", \"mean\")\n        )\n    )\n    df_ensemble_test_preds.to_csv(f\"./{model_name}/{model_name}_kfolds_ensemble_test_preds.csv\", index=False)\n\n    return {\n        \"df_eval_aucs\": df_eval_aucs,\n        \"df_eval_preds\": df_eval_preds,\n        \"all_df_folds_test_preds\": all_df_folds_test_preds,\n        \"df_ensemble_test_preds\": df_ensemble_test_preds,\n        \"models\": models\n    }","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_metrics_of_models(dataset_results: dict) -> None:\n    metrics_list = []\n    for model_name, model_results in dataset_results.items():\n        model_results[\"metrics\"]\n        metrics_list.append({\"model\": model_name, **model_results[\"metrics\"]})\n\n    df_metrics_list = pd.DataFrame(metrics_list)\n    df_metrics_list.set_index(\"model\", inplace=True)\n    df_metrics_list = df_metrics_list.sort_values(\n        by=\"eval_auc\",\n        ascending=False\n    )\n\n    display(df_metrics_list)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Results","metadata":{}},{"cell_type":"code","source":"results = {}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# t340","metadata":{}},{"cell_type":"code","source":"dataset_name = \"t340\"\nfeature_names = [\"rdkitfp\"]\nmodel_type = \"xgb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_name = \"t340\"\nfeature_names = [\"rdkitfp\", \"desc2D\"]\nmodel_type = \"hgb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# t450_679","metadata":{}},{"cell_type":"code","source":"dataset_name = \"t450_679\"\nfeature_names = [\"desc2D\"]\nmodel_type = \"cb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_name = \"t450_679\"\nfeature_names = [\"rdkitfp\"]\nmodel_type = \"cb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# f340_450","metadata":{}},{"cell_type":"code","source":"dataset_name = \"f340_450\"\nfeature_names = [\"rdkitfp\"]\nmodel_type = \"xgb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_name = \"f340_450\"\nfeature_names = [\"morganfp\"]\nmodel_type = \"hgb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_name = \"f340_450\"\nfeature_names = [\"rdkitfp\", \"desc2D\"]\nmodel_type = \"xgb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# fmulti","metadata":{}},{"cell_type":"code","source":"dataset_name = \"fmulti\"\nfeature_names = [\"rdkitfp\", \"desc2D\"]\nmodel_type = \"cb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_name = \"fmulti\"\nfeature_names = [\"maccskeys\"]\nmodel_type = \"xgb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset_name = \"fmulti\"\nfeature_names = [\"morganfp\", \"desc2D\"]\nmodel_type = \"cb\"\nmodel_name = dataset_name + \"_\" + model_type + \"_\" + \"_\".join(feature_names)\nos.makedirs(model_name, exist_ok=True)\n\nresults[model_name] = train_eval_skfold(\n    df_train_full,\n    df_test,\n    dataset_name,\n    X_train_features,\n    X_test_features,\n    feature_names,\n    model_type,\n    RANDOM_STATE\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!zip -r /kaggle/working/output.zip /kaggle/working/","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}